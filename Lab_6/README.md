### Задание 6 - 10 баллов

- Изучить [главу 3. Fine-tuning a pretrained model туториалов HuggingFace](https://huggingface.co/learn/nlp-course/chapter3/1)
- Выбрать модель архитектуры BERT/GPT в HuggingFace hub для решения задач Text Classification / Text Generation
- Выбрать набор данных для конкретной задачи из HuggingFace Datasets
- Дообучить выбранную модель - **5 баллов**
- Сравнить качество до и после дообучения с учетом метрик, специфичных для выбранной задачи - **2 балла**
- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **2 балла**

- Соблюден code style на уровне pep8 и [On writing clean Jupyter notebooks](https://ploomber.io/blog/clean-nbs/)  - **1 балл**

### [Ссылка на Colab](https://drive.google.com/file/d/1mnLrYVbEHCWLjP5dKznXCrAOyIBNmOl5/view?usp=sharing)